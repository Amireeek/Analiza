# -*- coding: utf-8 -*-

# ==============================================================================
# Krok 0: Instalacja bibliotek
# ==============================================================================
# pip install streamlit requests trafilatura google-generativeai scrapingbee
# ==============================================================================
# Krok 1: Import bibliotek
# ==============================================================================
import streamlit as st
import requests
import re
from trafilatura import extract
import google.generativeai as genai
from urllib.parse import urlencode as encode_query_params
import json
import time

# ==============================================================================
# Krok 2: Konfiguracja strony Streamlit
# ==============================================================================
st.set_page_config(page_title="SEO Content Powerhouse", page_icon="ğŸš€", layout="wide")
st.title("ğŸš€ SEO Content Powerhouse z AI")
st.markdown("NarzÄ™dzie do tworzenia kompletnych strategii contentowych na podstawie analizy TOP 10 wynikÃ³w Google.")

# ==============================================================================
# Krok 3: ObsÅ‚uga Kluczy API ze Streamlit Secrets
# ==============================================================================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    SCRAPINGBEE_API_KEY = st.secrets["SCRAPINGBEE_API_KEY"]
    DATAFORSEO_LOGIN = st.secrets["DATAFORSEO_LOGIN"]
    DATAFORSEO_PASSWORD = st.secrets["DATAFORSEO_PASSWORD"]

    genai.configure(api_key=GEMINI_API_KEY)

except KeyError as e:
    missing_key = str(e).strip("'")
    st.error(f"ğŸ›‘ BÅ‚Ä…d konfiguracji sekretÃ³w! Nie znaleziono wymaganego sekretu: {missing_key}. Upewnij siÄ™, Å¼e skonfigurowaÅ‚eÅ› GEMINI_API_KEY, SCRAPINGBEE_API_KEY, DATAFORSEO_LOGIN i DATAFORSEO_PASSWORD.")
    st.stop()
except Exception as e:
    st.error(f"ğŸ›‘ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d podczas Å‚adowania kluczy: {e}")
    st.stop()

# ==============================================================================
# Krok 4: Funkcje Backendowe
# ==============================================================================

@st.cache_data
def get_serp_data_with_dataforseo(login, password, query, num_results=10, location_code=2616, language_code='pl'):
    """
    Pobiera TYLKO wyniki organiczne wyszukiwania Google uÅ¼ywajÄ…c API DataForSEO.
    Zwraca listÄ™ wynikÃ³w organicznych.
    """
    post_data = [{"keyword": query, "location_code": location_code, "language_code": language_code, "depth": num_results}]
    headers = {'Content-Type': 'application/json'}
    endpoint_url = "https://api.dataforseo.com/v3/serp/google/organic/live/regular"
    organic_results_list = []
    try:
        response = requests.post(endpoint_url, auth=(login, password), headers=headers, json=post_data, timeout=60)
        response.raise_for_status()
        data = response.json()
        if data.get("status_code") == 20000 and data.get("tasks") and data["tasks"][0].get("result") and data["tasks"][0]["result"][0].get("items"):
            items = data["tasks"][0]["result"][0]["items"]
            for item in items:
                item_type = item.get("type")
                if item_type == "organic": # InteresujÄ… nas tylko wyniki organiczne
                    title, link = item.get("title"), item.get("url")
                    if title and link: organic_results_list.append({'title': title, 'link': link})
        else:
            status_message = data.get("status_message", "Nieznany bÅ‚Ä…d.")
            tasks_error = ""
            if data.get("tasks") and data["tasks"][0].get("status_message") != "Ok.":
                tasks_error = f" BÅ‚Ä…d zadania: {data['tasks'][0]['status_code']} - {data['tasks'][0]['status_message']}"
            st.warning(f"DataForSEO API zwrÃ³ciÅ‚o nieoczekiwany status lub brak wynikÃ³w: {status_message}{tasks_error}.")
        return organic_results_list # Zwracamy tylko listÄ™ wynikÃ³w organicznych
    except: # Uproszczona obsÅ‚uga bÅ‚Ä™dÃ³w
        return []


@st.cache_data
def scrape_and_clean_content(url_to_scrape, scrapingbee_api_key):
    """Pobiera i czyÅ›ci treÅ›Ä‡ ze strony uÅ¼ywajÄ…c ScrapingBee."""
    # (bez zmian)
    try:
        response = requests.get(
            url='https://app.scrapingbee.com/api/v1/',
            params={'api_key': scrapingbee_api_key, 'url': url_to_scrape, 'premium_proxy': 'true', 'block_resources': 'false'},
            timeout=90
        )
        response.raise_for_status()
        extracted_text = extract(response.text, include_comments=False, include_tables=False, include_images=False)
        if not extracted_text: return None
        cleaned_text = re.sub(r'\s+', ' ', extracted_text).strip()
        return cleaned_text if len(cleaned_text) > 100 else None
    except: return None

# --- Funkcje generujÄ…ce KAÅ»DÄ„ SEKCJÄ˜ RAPORTU ---
def generate_gemini_response(section_prompt, section_name):
    """WysyÅ‚a pojedynczy prompt do Gemini i zwraca odpowiedÅº."""
    # (bez zmian)
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        generation_config = genai.types.GenerationConfig(max_output_tokens=8192)
        response = model.generate_content(section_prompt, generation_config=generation_config)
        if hasattr(response, 'text') and response.text:
            return response.text.strip()
        else:
            st.warning(f"âš ï¸ Gemini zwrÃ³ciÅ‚o pustÄ… odpowiedÅº dla sekcji: {section_name}.")
            if hasattr(response, 'prompt_feedback'): st.write(f"Feedback dla {section_name}:", response.prompt_feedback)
            if hasattr(response, 'candidates') and response.candidates and response.candidates[0].finish_reason:
                 st.write(f"Przyczyna zakoÅ„czenia dla {section_name}:", response.candidates[0].finish_reason)
            return f"### {section_name}\nBrak danych od AI dla tej sekcji."
    except Exception as e:
        st.error(f"ğŸ›‘ BÅ‚Ä…d komunikacji z Gemini API dla sekcji {section_name}: {e}")
        return f"### {section_name}\nBÅ‚Ä…d generowania tej sekcji."

def generate_kluczowe_punkty(all_content, keyword_phrase):
    # (bez zmian)
    prompt = f"""Jako analityk SEO, przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ z artykuÅ‚Ã³w TOP10 dla frazy "{keyword_phrase}".
Twoim zadaniem jest TYLKO wygenerowanie sekcji "### 1. Kluczowe Punkty WspÃ³lne".
Wypunktuj tematy, podtematy, kluczowe informacje, perspektywy i style narracji, ktÃ³re powtarzajÄ… siÄ™ w wiÄ™kszoÅ›ci analizowanych tekstÃ³w. Skup siÄ™ na tym, co jest standardem i skonstruuj wytyczne dla copywritera. OdpowiedÅº musi byÄ‡ TYLKO treÅ›ciÄ… tej sekcji, zaczynajÄ…c od nagÅ‚Ã³wka `### 1. Kluczowe Punkty WspÃ³lne`.

TreÅ›Ä‡ do analizy:
{all_content if all_content else "Brak treÅ›ci z artykuÅ‚Ã³w TOP10 do analizy."}
"""
    return generate_gemini_response(prompt, "1. Kluczowe Punkty WspÃ³lne")

def generate_unikalne_elementy(all_content, keyword_phrase):
    # (bez zmian)
    prompt = f"""Jako analityk SEO, przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ z artykuÅ‚Ã³w TOP10 dla frazy "{keyword_phrase}".
Twoim zadaniem jest TYLKO wygenerowanie sekcji "### 2. Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy".
Wypunktuj nietypowe, oryginalne, innowacyjne lub szczegÃ³lnie wartoÅ›ciowe informacje, dane, przykÅ‚ady, case studies, infografiki (opisz co przedstawiajÄ…) lub perspektywy, ktÃ³re pojawiÅ‚y siÄ™ tylko w niektÃ³rych ÅºrÃ³dÅ‚ach z TOP10 i mogÄ… stanowiÄ‡ przewagÄ™ konkurencyjnÄ… dla nowego artykuÅ‚u. OdpowiedÅº musi byÄ‡ TYLKO treÅ›ciÄ… tej sekcji, zaczynajÄ…c od nagÅ‚Ã³wka `### 2. Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy`.

TreÅ›Ä‡ do analizy:
{all_content if all_content else "Brak treÅ›ci z artykuÅ‚Ã³w TOP10 do analizy."}
"""
    return generate_gemini_response(prompt, "2. Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy")

def generate_sÅ‚owa_kluczowe(all_content, keyword_phrase):
    # (bez zmian)
    prompt = f"""Jako analityk SEO, przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ z artykuÅ‚Ã³w TOP10 dla frazy "{keyword_phrase}".
Twoim zadaniem jest TYLKO wygenerowanie sekcji "### 3. Sugerowane SÅ‚owa Kluczowe i Semantyka".
Na podstawie analizy treÅ›ci konkurencji z TOP10, stwÃ³rz listÄ™ 10-12 najwaÅ¼niejszych sÅ‚Ã³w kluczowych, fraz dÅ‚ugoogonowych i pojÄ™Ä‡ semantycznie powiÄ…zanych. Pogrupuj je tematycznie, jeÅ›li to uÅ‚atwia zrozumienie. WskaÅ¼ intencjÄ™ wyszukiwania dla frazy gÅ‚Ã³wnej. OdpowiedÅº musi byÄ‡ TYLKO treÅ›ciÄ… tej sekcji, zaczynajÄ…c od nagÅ‚Ã³wka `### 3. Sugerowane SÅ‚owa Kluczowe i Semantyka`.

TreÅ›Ä‡ do analizy:
{all_content if all_content else "Brak treÅ›ci z artykuÅ‚Ã³w TOP10 do analizy."}
"""
    return generate_gemini_response(prompt, "3. Sugerowane SÅ‚owa Kluczowe i Semantyka")

def generate_struktura_artykulu(all_content, keyword_phrase):
    # --- ZMIANA TUTAJ: Jeszcze bardziej stanowcze instrukcje dotyczÄ…ce struktury ---
    prompt = f"""Jako ekspert SEO specjalizujÄ…cy siÄ™ w tworzeniu BARDZO SZCZEGÃ“ÅOWYCH i WYCZERPUJÄ„CYCH konspektÃ³w artykuÅ‚Ã³w, przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ z artykuÅ‚Ã³w TOP10 dla frazy "{keyword_phrase}".
Twoim zadaniem jest TYLKO wygenerowanie sekcji "### 4. Proponowana Struktura ArtykuÅ‚u (Szkic)".
Zaproponuj niezwykle rozbudowanÄ… i dogÅ‚Ä™bnÄ… strukturÄ™ nowego artykuÅ‚u w formacie Markdown. Struktura MUSI zawieraÄ‡:
1.  Co najmniej 2-3 propozycje chwytliwych tytuÅ‚Ã³w dla caÅ‚ego artykuÅ‚u, odpowiednich dla frazy "{keyword_phrase}".
2.  NastÄ™pnie, struktura MUSI byÄ‡ podzielona na **DOKÅADNIE 5 do 6 (piÄ™Ä‡ do szeÅ›ciu) GÅÃ“WNYCH SEKCJI (kaÅ¼da jako nagÅ‚Ã³wek H2)**.
3.  Dla **KAÅ»DEJ z tych gÅ‚Ã³wnych sekcji H2, MUSISZ zaproponowaÄ‡ **DOKÅADNIE 3 do 4 (trzy do czterech) bardziej szczegÃ³Å‚owych podpunktÃ³w (kaÅ¼dy jako nagÅ‚Ã³wek H3)**.
NagÅ‚Ã³wki H2 i H3 powinny byÄ‡ angaÅ¼ujÄ…ce, precyzyjnie opisywaÄ‡ zawartoÅ›Ä‡ danego fragmentu i naturalnie zawieraÄ‡ sÅ‚owa kluczowe, jeÅ›li to moÅ¼liwe. Dbaj o logiczny przepÅ‚yw i kompleksowe pokrycie tematu, czerpiÄ…c inspiracjÄ™ z analizy TOP10.
OdpowiedÅº musi byÄ‡ TYLKO treÅ›ciÄ… tej sekcji, zaczynajÄ…c od nagÅ‚Ã³wka `### 4. Proponowana Struktura ArtykuÅ‚u (Szkic)`.

TreÅ›Ä‡ do analizy:
{all_content if all_content else "Brak treÅ›ci z artykuÅ‚Ã³w TOP10 do analizy."}
"""
    return generate_gemini_response(prompt, "4. Proponowana Struktura ArtykuÅ‚u (Szkic)")

def generate_faq(all_content, keyword_phrase):
    # (bez zmian - instrukcja o odpowiedziach pod pytaniami juÅ¼ byÅ‚a)
    prompt = f"""Jako analityk SEO, przeanalizuj poniÅ¼szÄ… treÅ›Ä‡ z artykuÅ‚Ã³w TOP10 dla frazy "{keyword_phrase}".
Twoim zadaniem jest TYLKO wygenerowanie sekcji "### 5. Sekcja FAQ (Pytania i Odpowiedzi)".
StwÃ³rz listÄ™ 4-5 najczÄ™stszych pytaÅ„, na ktÃ³re odpowiadajÄ… konkurenci z TOP10, w stylu 'People Also Ask'. **Dla kaÅ¼dego pytania, podaj 2-3 zdaniowÄ… bezpoÅ›redniÄ… odpowiedÅº, piszÄ…c jÄ… BEZPOÅšREDNIO POD DANYM PYTANIEM, w nowej linii.** UÅ¼yj formatowania Markdown: pytanie jako zwykÅ‚y tekst lub pogrubiony, a odpowiedÅº pod nim. OdpowiedÅº musi byÄ‡ TYLKO treÅ›ciÄ… tej sekcji, zaczynajÄ…c od nagÅ‚Ã³wka `### 5. Sekcja FAQ (Pytania i Odpowiedzi)`.

TreÅ›Ä‡ do analizy:
{all_content if all_content else "Brak treÅ›ci z artykuÅ‚Ã³w TOP10 do analizy."}
"""
    return generate_gemini_response(prompt, "5. Sekcja FAQ (Pytania i Odpowiedzi)")

# Funkcja generate_wskazowki_sge nie jest juÅ¼ potrzebna, bo usuwamy tÄ™ sekcjÄ™

def parse_report(report_text):
    """Dzieli peÅ‚ny raport na sekcje do wyÅ›wietlenia w zakÅ‚adkach."""
    # (bez zmian)
    if not report_text: return {}
    sections = {}
    pattern = r"###\s*(?:\d+\.\s*)?(.*?)\n(.*?)(?=\n###\s*\d+\.|$|\Z)"
    matches = re.findall(pattern, report_text, re.DOTALL)
    for match in matches:
        title = match[0].strip()
        content = match[1].strip()
        if title and content:
            sections[title] = content
    return sections

# ==============================================================================
# Krok 5: Interfejs UÅ¼ytkownika i gÅ‚Ã³wna logika
# ==============================================================================
keyword = st.text_input("WprowadÅº frazÄ™ kluczowÄ…, ktÃ³rÄ… chcesz przeanalizowaÄ‡:", placeholder="np. jak dbaÄ‡ o buty skÃ³rzane")

if st.button("ğŸš€ Wygeneruj Kompleksowy Audyt SEO"):
    if not keyword:
        st.warning("ProszÄ™ wpisaÄ‡ frazÄ™ kluczowÄ….")
        st.stop()

    if 'SCRAPINGBEE_API_KEY' not in st.secrets or \
       'GEMINI_API_KEY' not in st.secrets or \
       'DATAFORSEO_LOGIN' not in st.secrets or \
       'DATAFORSEO_PASSWORD' not in st.secrets:
         st.error("BÅ‚Ä…d: Nie wszystkie wymagane klucze API sÄ… skonfigurowane w Streamlit Secrets.")
         st.stop()

    with st.spinner("Przeprowadzam peÅ‚ny audyt... To moÅ¼e potrwaÄ‡ kilka minut."):
        st.info("Etap 1/4: Pobieranie i filtrowanie wynikÃ³w z Google (przez DataForSEO)...")
        # --- ZMIANA TUTAJ: get_serp_data_with_dataforseo zwraca teraz tylko listÄ™ wynikÃ³w organicznych ---
        top_results = get_serp_data_with_dataforseo(DATAFORSEO_LOGIN, DATAFORSEO_PASSWORD, keyword)
        
        if not top_results: # JeÅ›li nie ma Å¼adnych wynikÃ³w organicznych
            st.error(f"Nie udaÅ‚o siÄ™ pobraÄ‡ wynikÃ³w organicznych z DataForSEO dla frazy '{keyword}'. Audyt przerwany.")
            st.stop()

        BANNED_DOMAINS = ["youtube.com", "pinterest.", "instagram.com", "facebook.com", "olx.pl", "allegro.pl", "twitter.com", "tiktok.com", "wikipedia.org", "sÅ‚ownik.pl", "encyklopedia.", "forum.", ".gov", ".edu", "otodom.pl", "gratka.pl", "domiporta.pl"]
        filtered_results = [r for r in top_results if r and r.get('link') and not any(b in r['link'].lower() for b in BANNED_DOMAINS)]

        if not filtered_results:
             st.error("Po filtracji nie pozostaÅ‚y Å¼adne artykuÅ‚y do analizy.")
             st.stop()
        
        if len(top_results) > len(filtered_results):
            st.info(f"PominiÄ™to {len(top_results) - len(filtered_results)} wynikÃ³w, analizujÄ™ {len(filtered_results)} artykuÅ‚Ã³w.")
        st.subheader("Analizowane adresy URL (po filtracji):")
        for i, r in enumerate(filtered_results, 1): st.write(f"{i}. [{r.get('title', r.get('link'))}]({r.get('link', '#')})")

        all_articles_content_str = ""
        if filtered_results: # Tylko jeÅ›li sÄ… artykuÅ‚y do scrapowania
            st.info("Etap 2/4: Pobieranie treÅ›ci ze stron (ScrapingBee)...")
            all_articles_content_list = []
            progress_bar = st.progress(0)
            for i, result in enumerate(filtered_results):
                url = result.get('link')
                if url:
                    content = scrape_and_clean_content(url, SCRAPINGBEE_API_KEY)
                    if content: all_articles_content_list.append(content)
                    progress_bar.progress((i + 1) / len(filtered_results))
            progress_bar.empty()
            if not all_articles_content_list: st.warning("Nie udaÅ‚o siÄ™ pobraÄ‡ treÅ›ci z Å¼adnej ze stron. Raport bÄ™dzie bazowaÅ‚ na dostÄ™pnych informacjach.")
            else:
                st.success(f"âœ… PomyÅ›lnie pobrano treÅ›ci z {len(all_articles_content_list)} stron.")
                all_articles_content_str = "\n\n---\n\n".join(all_articles_content_list)
        
        if not all_articles_content_str and not filtered_results: # JeÅ›li nie ma ani treÅ›ci, ani nawet linkÃ³w (co nie powinno siÄ™ zdarzyÄ‡ jeÅ›li filtered_results jest warunkiem)
            st.error("Brak treÅ›ci artykuÅ‚Ã³w do analizy. Audyt przerwany.")
            st.stop()

        st.info("Etap 3/4: Generowanie raportu przez AI (Gemini) - sekcja po sekcji...")
        report_parts = []
        report_progress = st.progress(0)
        
        # --- ZMIANA TUTAJ: UsuniÄ™to sekcjÄ™ SGE z listy generowania ---
        sections_to_generate = [
            ("1. Kluczowe Punkty WspÃ³lne", lambda: generate_kluczowe_punkty(all_articles_content_str, keyword)),
            ("2. Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy", lambda: generate_unikalne_elementy(all_articles_content_str, keyword)),
            ("3. Sugerowane SÅ‚owa Kluczowe i Semantyka", lambda: generate_sÅ‚owa_kluczowe(all_articles_content_str, keyword)),
            ("4. Proponowana Struktura ArtykuÅ‚u (Szkic)", lambda: generate_struktura_artykulu(all_articles_content_str, keyword)),
            ("5. Sekcja FAQ (Pytania i Odpowiedzi)", lambda: generate_faq(all_articles_content_str, keyword))
        ]
        total_sections = len(sections_to_generate)

        for i, (section_title, generation_func) in enumerate(sections_to_generate):
            st.write(f"Generowanie sekcji: {section_title}...") # Daje feedback uÅ¼ytkownikowi
            part = generation_func()
            report_parts.append(part)
            report_progress.progress((i + 1) / total_sections)
            # time.sleep(0.5) # MoÅ¼na przywrÃ³ciÄ‡, jeÅ›li API Gemini ma problemy z rate limiting

        full_report = "\n\n".join(report_parts)
        report_progress.empty()

        if not full_report or all(p.startswith("###") and "Brak danych" in p or "BÅ‚Ä…d generowania" in p for p in report_parts):
             st.error("Generowanie raportu przez Gemini nie powiodÅ‚o siÄ™ dla Å¼adnej sekcji lub zwrÃ³ciÅ‚o bÅ‚Ä™dy.")
             st.stop()

        st.info("Etap 4/4: Formatowanie wynikÃ³w...")
        report_sections = parse_report(full_report)
        
        st.balloons()
        st.success("âœ… Audyt SEO gotowy!")
        st.markdown(f"--- \n## Audyt SEO i plan treÅ›ci dla frazy: '{keyword}'")

        # --- ZMIANA TUTAJ: UsuniÄ™to sekcjÄ™ SGE i Analizowane Å¹rÃ³dÅ‚a z zakÅ‚adek ---
        preferred_tab_order = [
            "Kluczowe Punkty WspÃ³lne", "Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy",
            "Sugerowane SÅ‚owa Kluczowe i Semantyka", "Proponowana Struktura ArtykuÅ‚u (Szkic)",
            "Sekcja FAQ (Pytania i Odpowiedzi)"
        ]
        
        actual_tab_titles = [title for title in preferred_tab_order if title in report_sections and report_sections[title].strip()]
        
        if actual_tab_titles:
            tabs = st.tabs(actual_tab_titles)
            for i, tab_title in enumerate(actual_tab_titles): # Zmieniono mapowanie, aby byÅ‚o prostsze
                with tabs[i]:
                    st.header(tab_title)
                    st.markdown(report_sections[tab_title])
        else:
            st.warning("Brak danych do wyÅ›wietlenia w zakÅ‚adkach.")
else:
    if keyword: st.info(f"Wprowadzono frazÄ™: '{keyword}'. Kliknij przycisk powyÅ¼ej, aby rozpoczÄ…Ä‡ analizÄ™.")

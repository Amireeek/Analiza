# app.py - wersja z ulepszonym scraperem

import streamlit as st
import httpx  # U偶ywamy bardziej zaawansowanej biblioteki HTTP
from trafilatura import extract
import google.generativeai as genai
from googleapiclient.discovery import build

# --- Konfiguracja strony (bez zmian) ---
st.set_page_config(page_title="Analizator SERP z Gemini", page_icon="", layout="wide")
st.title(" Analizator SERP z AI")
st.markdown("Narzdzie do gbokiej analizy treci z TOP 10 wynik贸w Google przy u偶yciu Gemini 1.5 Pro.")

# --- Obsuga Kluczy API (bez zmian) ---
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    SEARCH_API_KEY = st.secrets["SEARCH_API_KEY"]
    SEARCH_ENGINE_ID = st.secrets["SEARCH_ENGINE_ID"]
    genai.configure(api_key=GEMINI_API_KEY)
except (KeyError, FileNotFoundError):
    st.error("Bd: Klucze API nie zostay znalezione. Upewnij si, 偶e skonfigurowae sekrety w Streamlit.")
    st.stop()

# --- Funkcje Backendowe (Z AKTUALIZACJ) ---
@st.cache_data
def get_top_10_results(api_key, cse_id, query):
    service = build("customsearch", "v1", developerKey=api_key)
    res = service.cse().list(q=query, cx=cse_id, num=10, gl='pl', hl='pl').execute()
    return res.get('items', [])

# --- ULEPSZONA FUNKCJA SCRAPINGU ---
@st.cache_data
def scrape_and_clean_content(url):
    # Nag贸wki udajce popularn przegldark na systemie Windows
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
        'Accept-Language': 'pl-PL,pl;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.google.com/'
    }
    try:
        # U偶ywamy httpx, kt贸ry jest nowoczesnym klientem HTTP
        with httpx.Client(headers=headers, follow_redirects=True, timeout=15) as client:
            response = client.get(url)
            # Sprawdzamy, czy serwer nie zwr贸ci bdu (np. 403, 500)
            response.raise_for_status()
            # Jeli wszystko jest OK, przekazujemy tre do trafilatura
            return extract(response.text, include_comments=False, include_tables=False)
    except httpx.HTTPStatusError as e:
        # Ten bd apie teraz 403 Forbidden i inne bdy HTTP
        st.warning(f"Nie udao si pobra treci z {url} (Bd HTTP: {e.response.status_code}). Strona prawdopodobnie blokuje boty.")
        return None
    except Exception as e:
        st.warning(f"Wystpi inny bd podczas pr贸by pobrania treci z {url}: {e}")
        return None

# --- Pozostae funkcje (bez zmian) ---
def analyze_content_with_gemini(all_content, keyword_phrase):
    if not all_content:
        return "Brak treci do analizy."
    
    prompt = f"""
    Jeste analitykiem SEO i ekspertem od strategii content marketingu. Twoim zadaniem jest dogbna analiza treci z najlepszych artyku贸w z polskiego Google dla frazy "{keyword_phrase}". Poni偶ej znajduje si zagregowana, oczyszczona tre tych artyku贸w.

    ---
    {all_content}
    ---

    Na podstawie powy偶szego materiau wykonaj nastpujce zadania:
    1.  **ZIDENTYFIKUJ KLUCZOWE PUNKTY WSPLNE:** Znajd藕 i wypunktuj tematy, zagadnienia i porady, kt贸re powtarzaj si w wikszoci artyku贸w.
    2.  **WSKA呕 UNIKALNE I WYR呕NIAJCE SI ELEMENTY:** Wypunktuj ciekawe, nietypowe informacje lub perspektywy, kt贸re pojawiy si tylko w niekt贸rych artykuach.
    3.  **SFORMUUJ WNIOSKI I REKOMENDACJE:** Stw贸rz list praktycznych wniosk贸w i rekomendacji dla osoby, kt贸ra chce napisa najlepszy, najbardziej kompletny artyku na ten temat.

    Sformatuj swoj odpowied藕 u偶ywajc Markdown (nag贸wki, listy, pogrubienia) dla maksymalnej czytelnoci.
    """
    
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
    response = model.generate_content(prompt)
    return response.text

# --- Interfejs U偶ytkownika (bez zmian) ---
keyword = st.text_input(
    "Wprowad藕 fraz kluczow, kt贸r chcesz przeanalizowa:",
    placeholder="np. jak zacz inwestowa mae kwoty"
)

if st.button(" Rozpocznij Analiz"):
    if keyword:
        with st.spinner("Trwa analiza... To mo偶e potrwa kilka minut. Prosz czeka."):
            st.write("Krok 1/3: Pobieranie listy TOP 10 wynik贸w z Google...")
            top_results = get_top_10_results(SEARCH_API_KEY, SEARCH_ENGINE_ID, keyword)
            
            if not top_results:
                st.error("Nie znaleziono wynik贸w dla tej frazy w Google.")
                st.stop()

            st.write("Krok 2/3: Pobieranie i czyszczenie treci z ka偶dej strony...")
            all_articles_content = []
            progress_bar = st.progress(0)
            for i, result in enumerate(top_results):
                url = result.get('link')
                content = scrape_and_clean_content(url)
                if content:
                    all_articles_content.append(content)
                progress_bar.progress((i + 1) / len(top_results))

            if not all_articles_content:
                st.error("Nie udao si pobra treci z 偶adnej ze stron. Spr贸buj inn fraz.")
                st.stop()

            st.write("Krok 3/3: Przekazywanie treci do analizy przez AI... To ostatni i najdu偶szy etap.")
            aggregated_content = "\n\n---\n\n".join(all_articles_content)
            analysis_report = analyze_content_with_gemini(aggregated_content, keyword)
            
            st.balloons()
            st.success("Analiza zakoczona!")
            
            st.markdown("---")
            st.markdown(f"## 娣卞害 Pena Analiza SERP dla frazy: '{keyword}'")
            st.markdown(analysis_report)
    else:
        st.warning("Prosz wpisa fraz kluczow.")

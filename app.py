# -*- coding: utf-8 -*-

# ==============================================================================
# Krok 0: Instalacja bibliotek
# ==============================================================================
# JeÅ›li uruchamiasz to lokalnie, upewnij siÄ™, Å¼e masz te biblioteki zainstalowane:
# pip install streamlit requests trafilatura google-generativeai google-api-python-client scrapingbee
# JeÅ›li uruchamiasz w Streamlit Cloud, dodaj je do pliku requirements.txt

# ==============================================================================
# Krok 1: Import bibliotek
# ==============================================================================
import streamlit as st
import requests
import re
from trafilatura import extract # Upewnij siÄ™, Å¼e masz tÄ™ bibliotekÄ™
import google.generativeai as genai
from googleapiclient.discovery import build # Upewnij siÄ™, Å¼e masz tÄ™ bibliotekÄ™


# ==============================================================================
# Krok 2: Konfiguracja strony Streamlit
# ==============================================================================
st.set_page_config(page_title="SEO Content Powerhouse", page_icon="ğŸš€", layout="wide")
st.title("ğŸš€ SEO Content Powerhouse z AI")
st.markdown("NarzÄ™dzie do tworzenia kompletnych strategii contentowych na podstawie analizy TOP 10 wynikÃ³w Google.")


# ==============================================================================
# Krok 3: ObsÅ‚uga Kluczy API ze Streamlit Secrets
# ==============================================================================
# WAÅ»NE: Upewnij siÄ™, Å¼e skonfigurowaÅ‚eÅ› WSZYSTKIE 4 klucze jako sekrety w Streamlit
try:
    # RÄ™cznie wpisz te linie, aby uniknÄ…Ä‡ problemÃ³w z niewidocznymi znakami!
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    SEARCH_API_KEY = st.secrets["SEARCH_API_KEY"]
    SEARCH_ENGINE_ID = st.secrets["SEARCH_ENGINE_ID"]
    SCRAPINGBEE_API_KEY = st.secrets["SCRAPINGBEE_API_KEY"] # Klucz ScrapingBee

    genai.configure(api_key=GEMINI_API_KEY)
    # Nie konfigurujemy od razu Google Search API, bo 'build' jest uÅ¼ywane w funkcji

    #st.success("âœ… Klucze API zaÅ‚adowane pomyÅ›lnie.") # MoÅ¼na odkomentowaÄ‡ dla debugowania

except KeyError as e:
    st.error(f"ğŸ›‘ BÅ‚Ä…d konfiguracji sekretÃ³w! Nie znaleziono wymaganego sekretu: {e}. Upewnij siÄ™, Å¼e skonfigurowaÅ‚eÅ› WSZYSTKIE 4 sekrety (GEMINI_API_KEY, SEARCH_API_KEY, SEARCH_ENGINE_ID, SCRAPINGBEE_API_KEY) w ustawieniach Streamlit.")
    st.stop() # Zatrzymaj dziaÅ‚anie aplikacji, jeÅ›li klucze nie sÄ… skonfigurowane
except Exception as e:
    st.error(f"ğŸ›‘ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d podczas Å‚adowania kluczy: {e}")
    st.stop()


# ==============================================================================
# Krok 4: Funkcje Backendowe
# ==============================================================================

@st.cache_data # Cache'owanie wynikÃ³w wyszukiwania Google
def get_top_10_results(api_key, cse_id, query):
    """Pobiera 10 najlepszych wynikÃ³w wyszukiwania Google dla danej frazy."""
    try:
        # UÅ¼ywamy wersji developera, ktÃ³ra wymaga klucza API
        service = build("customsearch", "v1", developerKey=api_key)
        # num=10 ogranicza wyniki do 10, gl/hl=pl ustawia region i jÄ™zyk na polski
        res = service.cse().list(q=query, cx=cse_id, num=10, gl='pl', hl='pl').execute()

        if 'items' not in res or not res['items']:
            # st.warning("Nie znaleziono Å¼adnych wynikÃ³w dla tej frazy.") # Komunikat bÄ™dzie niÅ¼ej w UI
            return []

        # Zwracamy listÄ™ sÅ‚ownikÃ³w z tytuÅ‚em i linkiem
        return [{'title': item.get('title'), 'link': item.get('link')} for item in res['items']]
    except Exception as e:
        st.error(f"ğŸ›‘ BÅ‚Ä…d podczas pobierania wynikÃ³w z Google Search API: {e}")
        # st.info("Upewnij siÄ™, Å¼e TwÃ³j SEARCH_API_KEY jest poprawny i wÅ‚Ä…czyÅ‚eÅ› Custom Search API w Google Cloud.") # MoÅ¼na dodaÄ‡ wiÄ™cej wskazÃ³wek
        return None # ZwrÃ³Ä‡ None w przypadku bÅ‚Ä™du, aby go obsÅ‚uÅ¼yÄ‡ dalej


@st.cache_data # Cache'owanie pobranej treÅ›ci
def scrape_and_clean_content(url_to_scrape, scrapingbee_api_key):
    """Pobiera i czyÅ›ci treÅ›Ä‡ ze strony uÅ¼ywajÄ…c ScrapingBee."""
    try:
        response = requests.get(
            url='https://app.scrapingbee.com/api/v1/',
            params={'api_key': scrapingbee_api_key, 'url': url_to_scrape, 'premium_proxy': 'true', 'block_resources': 'false'}, # Dodano block_resources
            timeout=90 # ZwiÄ™kszono timeout na wypadek wolnych stron
        )
        response.raise_for_status() # Rzuca wyjÄ…tek dla kodÃ³w bÅ‚Ä™dÃ³w HTTP (4xx, 5xx)

        # UÅ¼ywamy trafilatury do ekstrakcji czystego tekstu artykuÅ‚u
        # Upewnij siÄ™, Å¼e treÅ›Ä‡ response.text jest odpowiednia (np. zakodowana w UTF-8)
        extracted_text = extract(response.text, include_comments=False, include_tables=False, include_images=False) # WyÅ‚Ä…czono obrazy

        if not extracted_text:
             #st.warning(f"Trafilatura nie zwrÃ³ciÅ‚a treÅ›ci dla {url_to_scrape}") # Debug
             return None

        # Opcjonalnie: dodatkowe czyszczenie tekstu (np. usuniÄ™cie nadmiernych biaÅ‚ych znakÃ³w)
        cleaned_text = re.sub(r'\s+', ' ', extracted_text).strip()

        return cleaned_text if len(cleaned_text) > 100 else None # ZwrÃ³Ä‡ None jeÅ›li treÅ›Ä‡ jest za krÃ³tka

    except requests.exceptions.RequestException as e:
        st.warning(f"âš ï¸ Nie udaÅ‚o siÄ™ pobraÄ‡ treÅ›ci z {url_to_scrape} (ScrapingBee): {e}")
        return None
    except Exception as e:
        st.warning(f"âš ï¸ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d podczas przetwarzania treÅ›ci z {url_to_scrape}: {e}")
        return None


@st.cache_data(show_spinner="AI analizuje treÅ›Ä‡...") # Cache'owanie wynikÃ³w Gemini z innym spinnerem
def analyze_content_with_gemini(all_content, keyword_phrase):
    """Analizuje zagregowanÄ… treÅ›Ä‡ i generuje raport z Gemini."""
    if not all_content:
        return "Brak treÅ›ci do analizy przez AI."

    # === ZMODYFIKOWANY PROMPT ===
    prompt = f"""
JesteÅ› Å›wiatowej klasy analitykiem SEO i strategiem content marketingu. Twoim zadaniem jest przeanalizowanie dostarczonej treÅ›ci z czoÅ‚owych artykuÅ‚Ã³w dla frazy "{keyword_phrase}" i na tej podstawie wygenerowanie kompleksowego raportu w formacie Markdown.

Raport musi byÄ‡ podzielony na DOKÅADNIE nastÄ™pujÄ…ce sekcje, uÅ¼ywajÄ…c nagÅ‚Ã³wkÃ³w `### numer. Nazwa sekcji` i **Å¼adnych innych nagÅ‚Ã³wkÃ³w H3 w tytuÅ‚ach sekcji raportu**:

### 1. Kluczowe Punkty WspÃ³lne
(Wypunktuj tematy, podtematy, kluczowe informacje, perspektywy i style narracji, ktÃ³re powtarzajÄ… siÄ™ w wiÄ™kszoÅ›ci analizowanych tekstÃ³w. Skup siÄ™ na tym, co jest standardem w TOP 10 i skonstruuj wytyczne dla copywritera)

### 2. Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy
(Wypunktuj nietypowe, oryginalne, innowacyjne lub szczegÃ³lnie wartoÅ›ciowe informacje, dane, przykÅ‚ady, case studies, infografiki (opisz co przedstawiajÄ…) lub perspektywy, ktÃ³re pojawiÅ‚y siÄ™ tylko w niektÃ³rych ÅºrÃ³dÅ‚ach i mogÄ… stanowiÄ‡ przewagÄ™ konkurencyjnÄ… dla nowego artykuÅ‚u.)

### 3. Sugerowane SÅ‚owa Kluczowe i Semantyka
(Na podstawie analizy treÅ›ci konkurencji, stwÃ³rz listÄ™ 10-12 najwaÅ¼niejszych sÅ‚Ã³w kluczowych, fraz dÅ‚ugoogonowych i pojÄ™Ä‡ semantycznie powiÄ…zanych. Pogrupuj je tematycznie, jeÅ›li to uÅ‚atwia zrozumienie. WskaÅ¼ intencjÄ™ wyszukiwania dla frazy gÅ‚Ã³wnej.)

### 4. Proponowana Struktura ArtykuÅ‚u (Szkic)
(Zaproponuj idealnÄ…, rozbudowanÄ… strukturÄ™ nowego artykuÅ‚u w formacie Markdown. UÅ¼yj nagÅ‚Ã³wkÃ³w drugiego poziomu (`##`) dla gÅ‚Ã³wnych sekcji i nagÅ‚Ã³wkÃ³w trzeciego poziomu (`###`) dla podpunktÃ³w. Zaproponuj kilka nagÅ‚Ã³wkÃ³w do artykuÅ‚u, zawierajÄ…cych **okoÅ‚o 3 nagÅ‚Ã³wki H2 i 1 nagÅ‚Ã³wek H3 jako przykÅ‚ad hierarchii**. UwzglÄ™dnij kluczowe punkty, unikalne elementy i semantykÄ™ z analizy.)

### 5. Sekcja FAQ (Pytania i Odpowiedzi)
(StwÃ³rz listÄ™ 4-5 najczÄ™stszych pytaÅ„, na ktÃ³re odpowiadajÄ… konkurenci, w stylu 'People Also Ask'. Podaj 2-3 zdaniowe bezpoÅ›rednie odpowiedzi na te pytania, bazujÄ…c na analizowanej treÅ›ci. Odpowiedzi napisz pod pytaniami)


PamiÄ™taj, aby Twoja odpowiedÅº byÅ‚a TYLKO treÅ›ciÄ… raportu w formacie Markdown, bez Å¼adnych dodatkowych wstÄ™pÃ³w czy podsumowaÅ„ poza strukturÄ… raportu. CaÅ‚a odpowiedÅº musi byÄ‡ w jÄ™zyku polskim.
TreÅ›Ä‡ do analizy:
{all_content}
"""
    # === KONIEC ZMODYFIKOWANEGO PROMPTU ===

    try:
        # UÅ¼ywamy modelu gemini-1.5-flash-latest dla szybkoÅ›ci i kosztÃ³w
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = model.generate_content(prompt)

        # Sprawdzenie, czy odpowiedÅº zawiera treÅ›Ä‡
        if hasattr(response, 'text') and response.text:
             return response.text
        else:
             st.warning("âš ï¸ Gemini zwrÃ³ciÅ‚o pustÄ… odpowiedÅº lub bÅ‚Ä…d. SprÃ³buj ponownie lub zmieÅ„ prompt.")
             # Dodatkowe informacje o bÅ‚Ä™dzie z API Gemini
             if hasattr(response, 'prompt_feedback'):
                 st.write("Feedback z promptu:", response.prompt_feedback)
             if hasattr(response, 'candidates') and response.candidates:
                  if response.candidates[0].finish_reason:
                    st.write("Przyczyna zakoÅ„czenia generacji przez API:", response.candidates[0].finish_reason)
                  if hasattr(response.candidates[0], 'safety_ratings'):
                     st.write("Oceny bezpieczeÅ„stwa:", response.candidates[0].safety_ratings)

             return None


    except Exception as e:
        st.error(f"ğŸ›‘ BÅ‚Ä…d podczas komunikacji z Gemini API: {e}")
        # st.info("Upewnij siÄ™, Å¼e TwÃ³j GEMINI_API_KEY jest poprawny i masz dostÄ™p do modelu 'gemini-1.5-flash-latest'.") # WskazÃ³wka
        return None


# --- Funkcja do parsowania raportu (bez zmian) ---
# Regex nadal dziaÅ‚a, bo format nagÅ‚Ã³wkÃ³w ### numer. Nazwa sekcji jest zachowany
def parse_report(report_text):
    """Dzieli peÅ‚ny raport na sekcje do wyÅ›wietlenia w zakÅ‚adkach."""
    if not report_text: return {}
    sections = {}
    # WyraÅ¼enie regularne do znalezienia treÅ›ci pomiÄ™dzy nagÅ‚Ã³wkami ###
    pattern = r"###\s*(?:\d+\.\s*)?(.*?)\n(.*?)(?=\n###\s*|$|\Z)"

    matches = re.findall(pattern, report_text, re.DOTALL)

    for match in matches:
        title = match[0].strip()
        content = match[1].strip()
        if title:
            sections[title] = content

    return sections


# ==============================================================================
# Krok 5: Interfejs UÅ¼ytkownika i gÅ‚Ã³wna logika
# ==============================================================================

# Pole formularza do wprowadzenia frazy
keyword = st.text_input("WprowadÅº frazÄ™ kluczowÄ…, ktÃ³rÄ… chcesz przeanalizowaÄ‡:", placeholder="np. jak dbaÄ‡ o buty skÃ³rzane")

# Przycisk do uruchomienia analizy
if st.button("ğŸš€ Wygeneruj Kompleksowy Audyt SEO"):
    if not keyword:
        st.warning("ProszÄ™ wpisaÄ‡ frazÄ™ kluczowÄ….")
        st.stop()

    # Sprawdzenie, czy klucze sÄ… dostÄ™pne przed rozpoczÄ™ciem
    # Ta logika zostaÅ‚a juÅ¼ czÄ™Å›ciowo obsÅ‚uÅ¼ona przez blok try/except na gÃ³rze
    if 'GEMINI_API_KEY' not in st.secrets or 'SEARCH_API_KEY' not in st.secrets or 'SEARCH_ENGINE_ID' not in st.secrets or 'SCRAPINGBEE_API_KEY' not in st.secrets:
         st.error("BÅ‚Ä…d: Nie wszystkie klucze API sÄ… skonfigurowane w Streamlit Secrets.")
         st.stop()

    # ========================================================================
    # >>> POCZÄ„TEK WPROWADZONEJ ZMIANY <<<
    # Wymuszenie dokÅ‚adnego dopasowania poprzez opakowanie frazy w cudzysÅ‚Ã³w.
    # UWAGA: To znacznie zawÄ™Å¼a wyszukiwanie i czÄ™sto moÅ¼e prowadziÄ‡ do braku wynikÃ³w.
    exact_query = f'"{keyword}"'
    st.info(f"WÅ‚Ä…czono tryb dokÅ‚adnego wyszukiwania. Wyszukiwana fraza: {exact_query}")
    # ========================================================================


    with st.spinner("Przeprowadzam peÅ‚ny audyt... To moÅ¼e potrwaÄ‡ kilka minut."):

        # Etap 1: Pobieranie wynikÃ³w z Google
        st.info("Etap 1/4: Pobieranie i filtrowanie wynikÃ³w z Google...")
        # UÅ¼ywamy zmodyfikowanej zmiennej `exact_query` do wyszukiwania
        top_results = get_top_10_results(SEARCH_API_KEY, SEARCH_ENGINE_ID, exact_query)
        # >>> KONIEC WPROWADZONEJ ZMIANY <<<
        # ========================================================================

        if not top_results:
            st.error(f"Nie znaleziono Å¼adnych wynikÃ³w TOP 10 dla DOKÅADNEJ frazy: '{keyword}'. SprÃ³buj uÅ¼yÄ‡ bardziej ogÃ³lnej frazy lub wyÅ‚Ä…cz tryb dokÅ‚adnego dopasowania w kodzie.")
            st.stop()

        # Filtrowanie wynikÃ³w (jak w Twoim kodzie)
        # Rozszerzona lista domen do banowania
        BANNED_DOMAINS = [
            "youtube.com", "pinterest.", "instagram.com", "facebook.com",
            "olx.pl", "allegro.pl", "twitter.com", "tiktok.com",
            "wikipedia.org", "sÅ‚ownik.pl", "encyklopedia.", "forum.", # Dodano przykÅ‚adowe filtry ogÃ³lne
            ".gov", ".edu", # CzÄ™sto pomijane w analizach komercyjnych
            "otodom.pl", "gratka.pl", "domiporta.pl" # PrzykÅ‚ady dla fraz nieruchomoÅ›ciowych
        ]
        # Filtrujemy wyniki, upewniajÄ…c siÄ™, Å¼e link istnieje i nie jest None/pusty
        filtered_results = [r for r in top_results if r and r.get('link') and not any(b in r['link'].lower() for b in BANNED_DOMAINS)] # .lower() dla bezpieczeÅ„stwa

        if not filtered_results:
            st.error("Po filtracji nie pozostaÅ‚y Å¼adne artykuÅ‚y do analizy (usuniÄ™to strony wideo, social media, sklepy, fora, Wikipedia, ogÅ‚oszenia, itp.).")
            st.stop()

        # Informacja o filtracji
        if len(top_results) > len(filtered_results):
             st.info(f"PominiÄ™to {len(top_results) - len(filtered_results)} wynikÃ³w, analizujÄ™ {len(filtered_results)} znalezionych artykuÅ‚Ã³w.")

        st.subheader("Analizowane adresy URL (po filtracji):")
        for i, result in enumerate(filtered_results, 1):
             # Dodano zabezpieczenie get() na wypadek braku tytuÅ‚u, wyÅ›wietlamy link jako fallback
            display_title = result.get('title', result.get('link', f"Brak tytuÅ‚u dla {result.get('link', 'nieznany URL')}"))
            st.write(f"{i}. [{display_title}]({result.get('link', '#')})")


        # Etap 2: Scraping treÅ›ci
        st.info("Etap 2/4: Pobieranie treÅ›ci ze stron przez Scraping API...")
        all_articles_content, successful_sources = [], []
        # UÅ¼ywamy klucza ScrapingBee w wywoÅ‚aniu funkcji
        progress_bar = st.progress(0)
        for i, result in enumerate(filtered_results):
             url = result.get('link')
             if url: # Upewnij siÄ™, Å¼e URL istnieje po filtracji
                 content = scrape_and_clean_content(url, SCRAPINGBEE_API_KEY)
                 if content:
                     all_articles_content.append(content)
                     successful_sources.append({'title': result.get('title', 'Brak tytuÅ‚u'), 'link': url})
                 progress_bar.progress((i + 1) / len(filtered_results))
        progress_bar.empty() # Ukryj pasek postÄ™pu po zakoÅ„czeniu

        if not all_articles_content:
            st.error("Nie udaÅ‚o siÄ™ pobraÄ‡ treÅ›ci z Å¼adnej ze stron przy uÅ¼yciu ScrapingBee. SprawdÅº klucz API ScrapingBee, limity lub dostÄ™pnoÅ›Ä‡ stron. Czasami problemem sÄ… teÅ¼ bardzo rozbudowane strony.")
            st.stop()

        st.success(f"âœ… PomyÅ›lnie pobrano treÅ›ci z {len(all_articles_content)} stron.")


        # Etap 3: Analiza AI
        st.info("Etap 3/4: Generowanie kompleksowego raportu przez AI...")
        aggregated_content = "\n\n---\n\n".join(all_articles_content) # PoÅ‚Ä…cz pobrane treÅ›ci
        # Przekazujemy zagregowanÄ… treÅ›Ä‡ i ORYGINALNÄ„ frazÄ™ kluczowÄ… (keyword) do Gemini
        full_report = analyze_content_with_gemini(aggregated_content, keyword)

        if not full_report:
             st.error("Generowanie raportu przez Gemini nie powiodÅ‚o siÄ™. SprawdÅº logi lub sprÃ³buj z innÄ… frazÄ…/kluczami API.")
             st.stop()


        # Etap 4: Formatowanie wynikÃ³w
        st.info("Etap 4/4: Formatowanie wynikÃ³w...")
        # Parsowanie odpowiedzi Gemini na sekcje
        report_sections = parse_report(full_report)

        # === RÄ˜CZNE DODANIE SEKcji Z ANALIZOWANYMI Å¹RÃ“DÅAMI ===
        # Zawsze dodajemy tÄ™ sekcjÄ™ do sÅ‚ownika report_sections
        sources_text = "\n".join([f"- [{source['title']}]({source['link']})" for source in successful_sources])
        report_sections["Analizowane Å¹rÃ³dÅ‚a"] = "PoniÅ¼ej lista adresÃ³w URL, ktÃ³rych treÅ›Ä‡ zostaÅ‚a pomyÅ›lnie pobrana i przeanalizowana przez AI:\n" + sources_text


        st.balloons()
        st.success("âœ… Audyt SEO gotowy!")

        st.markdown(f"--- \n## Audyt SEO i plan treÅ›ci dla frazy: '{keyword}'")

        # --- Interfejs z zakÅ‚adkami: DYNAMICZNE TWORZENIE ZAKÅADEK ---
        # Definiujemy preferowanÄ… kolejnoÅ›Ä‡ wszystkich MOÅ»LIWYCH zakÅ‚adek
        # Ta lista decyduje o kolejnoÅ›ci wyÅ›wietlania, jeÅ›li sekcja istnieje.
        preferred_tab_order = [
            "Kluczowe Punkty WspÃ³lne",
            "Unikalne i WyrÃ³Å¼niajÄ…ce SiÄ™ Elementy",
            "Sugerowane SÅ‚owa Kluczowe i Semantyka",
            "Proponowana Struktura ArtykuÅ‚u (Szkic)",
            "Sekcja FAQ (Pytania i Odpowiedzi)",
            "Wnioski i Rekomendacje", # Zachowujemy na liÅ›cie preferowanej kolejnoÅ›ci, ale zakÅ‚adka pojawi siÄ™ tylko jeÅ›li Gemini jÄ… wygeneruje (co przy obecnym prompcie siÄ™ nie stanie) LUB jeÅ›li dodalibyÅ›my jÄ… rÄ™cznie.
            "Analizowane Å¹rÃ³dÅ‚a" # Sekcja dodawana rÄ™cznie
        ]

        # Tworzymy listÄ™ tytuÅ‚Ã³w zakÅ‚adek, ktÃ³re faktycznie istniejÄ… w naszym sÅ‚owniku report_sections,
        # zachowujÄ…c preferowanÄ… kolejnoÅ›Ä‡.
        actual_tab_titles = [
            title for title in preferred_tab_order if title in report_sections and report_sections[title].strip() # Dodatkowo sprawdzamy, czy treÅ›Ä‡ nie jest pusta po strip()
        ]

        # Tworzenie zakÅ‚adek dynamicznie na podstawie ISTNIEJÄ„CYCH i NIEPUSTYCH sekcji
        if actual_tab_titles:
             # Usuwamy sekcjÄ™ "Analizowane Å¹rÃ³dÅ‚a" z listy, Å¼eby dodaÄ‡ jÄ… na koÅ„cu niezaleÅ¼nie od kolejnoÅ›ci z preferred_tab_order
             # Robimy to, Å¼eby mieÄ‡ pewnoÅ›Ä‡, Å¼e jest ZAWSZE na koÅ„cu.
             sources_tab_title = "Analizowane Å¹rÃ³dÅ‚a"
             if sources_tab_title in actual_tab_titles:
                  actual_tab_titles.remove(sources_tab_title)


             tabs = st.tabs(actual_tab_titles + [sources_tab_title] if sources_tab_title in report_sections and report_sections[sources_tab_title].strip() else actual_tab_titles) # Dodajemy zakÅ‚adkÄ™ ÅºrÃ³deÅ‚ na koÅ„cu, jeÅ›li ma treÅ›Ä‡


             # Przypisujemy tytuÅ‚y do indeksÃ³w zakÅ‚adek w celu poprawnego wyÅ›wietlania
             # Tworzymy mapowanie indeks -> tytuÅ‚
             tab_title_map = {i: title for i, title in enumerate(actual_tab_titles + [sources_tab_title] if sources_tab_title in report_sections and report_sections[sources_tab_title].strip() else actual_tab_titles)}


             for i in range(len(tabs)):
                 with tabs[i]:
                     current_title = tab_title_map[i]
                     st.header(current_title) # Dodaj nagÅ‚Ã³wek w kaÅ¼dej zakÅ‚adce dla jasnoÅ›ci
                     # Pobierz treÅ›Ä‡ z report_sections (wiemy, Å¼e klucz istnieje i nie jest pusty)
                     st.markdown(report_sections[current_title])
        else:
             st.warning("Brak danych do wyÅ›wietlenia w zakÅ‚adkach. SprawdÅº odpowiedÅº Gemini. MoÅ¼liwe, Å¼e API nie zwrÃ³ciÅ‚o Å¼adnej treÅ›ci lub wszystkie sekcje sÄ… puste.")


    # Koniec bloku if st.button("ğŸš€ Wygeneruj..."):
else:
    # Komunikat poczÄ…tkowy przed klikniÄ™ciem przycisku
    if keyword:
         st.info(f"Wprowadzono frazÄ™: '{keyword}'. Kliknij przycisk powyÅ¼ej, aby rozpoczÄ…Ä‡ analizÄ™.")
    # else: komunikat z text_input placeholder wystarczy
